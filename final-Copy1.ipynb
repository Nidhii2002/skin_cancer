{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f53b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76119b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbeee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_df = pd.read_csv('HAM/HAM10000_metadata.csv')\n",
    "\n",
    "SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df1fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
     ]
    }
   ],
   "source": [
    "# label encoding to numeric values from text\n",
    "le = LabelEncoder()\n",
    "le.fit(skin_df['dx'])\n",
    "LabelEncoder()\n",
    "print(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577419a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lesion_id      image_id   dx    dx_type   age     sex  \\\n",
      "1617  HAM_0007180  ISIC_0033272  mel      histo  65.0    male   \n",
      "8128  HAM_0007195  ISIC_0031923   nv      histo  40.0  female   \n",
      "2168  HAM_0001835  ISIC_0026652  mel      histo  65.0    male   \n",
      "1090  HAM_0000465  ISIC_0030583  bkl  consensus  35.0  female   \n",
      "7754  HAM_0001720  ISIC_0034010   nv      histo  45.0    male   \n",
      "8071  HAM_0006333  ISIC_0024424   nv      histo  35.0    male   \n",
      "7423  HAM_0004548  ISIC_0032832   nv      histo  45.0  female   \n",
      "8984  HAM_0006526  ISIC_0026671   nv      histo  55.0    male   \n",
      "2310  HAM_0003102  ISIC_0032389  mel      histo  65.0    male   \n",
      "7256  HAM_0004260  ISIC_0025525   nv      histo  65.0    male   \n",
      "\n",
      "         localization  label  \n",
      "1617             face      4  \n",
      "8128  lower extremity      5  \n",
      "2168             back      4  \n",
      "1090            trunk      2  \n",
      "7754          abdomen      5  \n",
      "8071            trunk      5  \n",
      "7423  upper extremity      5  \n",
      "8984  lower extremity      5  \n",
      "2310             face      4  \n",
      "7256             back      5  \n"
     ]
    }
   ],
   "source": [
    "skin_df['label'] = le.transform(skin_df[\"dx\"]) \n",
    "print(skin_df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ca1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution visualization\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "skin_df['dx'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Cell Type');\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "skin_df['sex'].value_counts().plot(kind='bar', ax=ax2)\n",
    "ax2.set_ylabel('Count', size=15)\n",
    "ax2.set_title('Sex');\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "skin_df['localization'].value_counts().plot(kind='bar')\n",
    "ax3.set_ylabel('Count',size=12)\n",
    "ax3.set_title('Localization')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "sample_age = skin_df[pd.notnull(skin_df['age'])]\n",
    "sns.distplot(sample_age['age'], fit=stats.norm, color='red');\n",
    "ax4.set_title('Age')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87cf9736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    6705\n",
      "4    1113\n",
      "2    1099\n",
      "1     514\n",
      "0     327\n",
      "6     142\n",
      "3     115\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Distribution of data into various classes \n",
    "from sklearn.utils import resample\n",
    "print(skin_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b53190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    500\n",
      "1    500\n",
      "2    500\n",
      "3    500\n",
      "4    500\n",
      "5    500\n",
      "6    500\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Balance data.\n",
    "# Many ways to balance data... you can also try assigning weights during model.fit\n",
    "#Separate each classes, resample, and combine back into single dataframe\n",
    "\n",
    "df_0 = skin_df[skin_df['label'] == 0]\n",
    "df_1 = skin_df[skin_df['label'] == 1]\n",
    "df_2 = skin_df[skin_df['label'] == 2]\n",
    "df_3 = skin_df[skin_df['label'] == 3]\n",
    "df_4 = skin_df[skin_df['label'] == 4]\n",
    "df_5 = skin_df[skin_df['label'] == 5]\n",
    "df_6 = skin_df[skin_df['label'] == 6]\n",
    "\n",
    "n_samples=500 \n",
    "df_0_balanced = resample(df_0, replace=True, n_samples=n_samples, random_state=42) \n",
    "df_1_balanced = resample(df_1, replace=True, n_samples=n_samples, random_state=42) \n",
    "df_2_balanced = resample(df_2, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_3_balanced = resample(df_3, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_4_balanced = resample(df_4, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_5_balanced = resample(df_5, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_6_balanced = resample(df_6, replace=True, n_samples=n_samples, random_state=42)\n",
    "\n",
    "#Combined back to a single dataframe\n",
    "skin_df_balanced = pd.concat([df_0_balanced, df_1_balanced, \n",
    "                              df_2_balanced, df_3_balanced, \n",
    "                              df_4_balanced, df_5_balanced, df_6_balanced])\n",
    "\n",
    "#Check the distribution. All classes should be balanced now.\n",
    "print(skin_df_balanced['label'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e154cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now time to read images based on image ID from the CSV file\n",
    "#This is the safest way to read images as it ensures the right image is read for the right ID\n",
    "image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join('HAM/', '*', '*.jpg'))}\n",
    "\n",
    "#Define the path and add as a new column\n",
    "skin_df_balanced['path'] = skin_df['image_id'].map(image_path.get)\n",
    "#Use the path to read images.\n",
    "skin_df_balanced['image'] = skin_df_balanced['path'].map(lambda x: np.asarray(Image.open(x).resize((SIZE,SIZE))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6731e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5  # number of samples for plotting\n",
    "# Plotting\n",
    "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
    "for n_axs, (type_name, type_rows) in zip(m_axs, \n",
    "                                         skin_df_balanced.sort_values(['dx']).groupby('dx')):\n",
    "    n_axs[0].set_title(type_name)\n",
    "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
    "        c_ax.imshow(c_row['image'])\n",
    "        c_ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1fa26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe column of images into numpy array\n",
    "X = np.asarray(skin_df_balanced['image'].tolist())\n",
    "X = X/255.  # Scale values to 0-1. You can also used standardscaler or other scaling methods.\n",
    "Y=skin_df_balanced['label']  #Assign label values to Y\n",
    "Y_cat = to_categorical(Y, num_classes=7) #Convert to categorical as this is a multiclass classification problem\n",
    "#Split to training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_cat, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5edd77ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 256)       7168      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 16, 16, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 14, 14, 128)       295040    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 5, 5, 64)          73792     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 2, 2, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 384,455\n",
      "Trainable params: 384,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "165/165 - 41s - loss: 1.8822 - acc: 0.2217 - val_loss: 1.8325 - val_acc: 0.2160 - 41s/epoch - 249ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d148113940>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the model.\n",
    "#I've used autokeras to find out the best model for this problem.\n",
    "#You can also load pretrained networks such as mobilenet or VGG16\n",
    "\n",
    "num_classes = 7\n",
    "inputs_shape = (16,32,32,3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, (3, 3),padding=\"same\",strides=1, activation=\"relu\", input_shape = (SIZE,SIZE,3) ))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))  \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3),activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))  \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))  \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=1,\n",
    "    batch_size = 16,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=2)\n",
    "\n",
    "# model.save('try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9a1e81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(32, 32, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11276/2859948304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skin.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "new_model = keras.models.load_model('sec.h5')\n",
    "\n",
    "def prepare(filepath):\n",
    "    SIZE = 32\n",
    "    x = Image.open(filepath)\n",
    "    z = x.convert('RGB')\n",
    "    result = z.resize((SIZE,SIZE))\n",
    "    return np.asarray(result)\n",
    "\n",
    "pre = new_model.predict(prepare('skin.jpg'))\n",
    "print([pre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21cb5f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
      "        0.000000e+00, 1.000000e+00, 3.566125e-17]], dtype=float32)]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "Melanocytic nevi\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# from PIL import Image\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "CATEGORIES = [\"Actinic keratoses\", \"Basal cell carcinoma\", \"Benign keratosis-like lesions\",\n",
    "             \"Dermatofibroma\", \"Melanoma\", \"Melanocytic nevi\", \"Vascular lesions\"]\n",
    "\n",
    "new_model = keras.models.load_model('sec.h5')\n",
    "\n",
    "test = image.load_img('skin.jpg',target_size = (32,32,3))\n",
    "test = image.img_to_array(test)\n",
    "test = np.expand_dims(test, axis = 0)\n",
    "\n",
    "pre = new_model.predict(test)\n",
    "print([pre])\n",
    "\n",
    "float_arr = pre[0]\n",
    "# arr = float_arr.astype(int)\n",
    "arr = np.around(float_arr)\n",
    "print(arr)\n",
    "\n",
    "li = arr.tolist()\n",
    "# result = li.index(1)\n",
    "res = max(li)\n",
    "result = li.index(res)\n",
    "\n",
    "print(CATEGORIES[result])\n",
    "\n",
    "# print(CATEGORIES[int(pre[0][0])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa16f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare(filepath):\n",
    "#     SIZE = 32\n",
    "#     x = Image.open(filepath)\n",
    "#     result = x.resize((SIZE,SIZE))\n",
    "#     return np.asarray(result).reshape(-1,SIZE,1)\n",
    "\n",
    "\n",
    "   \n",
    "# def prepare(filepath):\n",
    "#     SIZE = 32\n",
    "#     img_arr = cv2.imread(filepath, cv2.IMREAD_RGB)\n",
    "#     new_arr = cv2.resize(img_arr, (SIZE,SIZE))\n",
    "#     return new_arr.reshape(-1,SIZE,SIZE,1)\n",
    "    \n",
    "    \n",
    "                        \n",
    "\n",
    "# Show the model architecture\n",
    "#new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f3414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73e42ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021C70C7E970>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/cv2/\n",
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "!pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc58243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test data\n",
    "y_pred = model.predict(x_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "y_pred_classes = np.argmax(y_pred, axis = 1) \n",
    "# Convert test data to one hot vectors\n",
    "y_true = np.argmax(y_test, axis = 1) \n",
    "\n",
    "#Print confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(cm, annot=True, linewidths=.5, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac596d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot fractional incorrect misclassifications\n",
    "incorr_fraction = 1 - np.diag(cm) / np.sum(cm, axis=1)\n",
    "plt.bar(np.arange(7), incorr_fraction)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction of incorrect predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf454aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save the model\n",
    "# model.save('cifar_model.h5')\n",
    "\n",
    "\n",
    "# score = model.evaluate(x_valid, y_valid)\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16db6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
